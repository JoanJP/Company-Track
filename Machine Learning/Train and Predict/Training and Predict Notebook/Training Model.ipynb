{"cells":[{"cell_type":"markdown","metadata":{"id":"Qe6mHc20Fg_2"},"source":["# Data Aggregation"]},{"cell_type":"markdown","metadata":{"id":"rI83bq4IFg_4"},"source":["## Import Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"agYoEEpWFg_5"},"outputs":[],"source":["import pandas as pd\n","import datetime"]},{"cell_type":"markdown","metadata":{"id":"AS5_Raq7Fg_5"},"source":["## Import Datasets"]},{"cell_type":"markdown","metadata":{"id":"2W_C6DA5Fg_6"},"source":["### Main"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1PZsM65QFg_6"},"outputs":[],"source":["Order_df = pd.read_csv('./dataset/Order_clean.csv')\n","Order_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i2yJ3FRiFg_6"},"outputs":[],"source":["OrderItem_df = pd.read_csv('./dataset/OrderItem_clean.csv')\n","OrderItem_df.head()"]},{"cell_type":"markdown","metadata":{"id":"hztAa-h1Fg_6"},"source":["### Extra"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"waN9ur2kFg_6"},"outputs":[],"source":["Holiday_df = pd.read_csv('./dataset/Holidays.csv')\n","Holiday_df = Holiday_df.astype({'Date': 'datetime64[ns]'})\n","Holiday_df"]},{"cell_type":"markdown","metadata":{"id":"56dB3Y1VFg_7"},"source":["## Data Aggregation"]},{"cell_type":"markdown","metadata":{"id":"aeUQFMbhFg_7"},"source":["### Merged"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1TETV9G5Fg_7"},"outputs":[],"source":["Merged_df = pd.merge(OrderItem_df, Order_df, on='POSNo')\n","Merged_df"]},{"cell_type":"markdown","metadata":{"id":"gxa_bZA7Fg_7"},"source":["### Daily"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C4gELGCdFg_7"},"outputs":[],"source":["Daily_df = Merged_df.groupby(['BranchID','ItemID','POSDate']).agg({'Qty': 'sum', 'Price': 'first', 'Discount': 'sum'}).sort_values(by=['BranchID','ItemID']).reset_index()\n","Daily_df = Daily_df.rename(columns={'Qty': 'Qty_sum', 'Price': 'PricePerItem'})\n","Daily_df = Daily_df.astype({'POSDate': 'datetime64[ns]'})\n","Daily_df['Discount'] = Daily_df['Discount'].map(bool)\n","cols = ['BranchID','ItemID','POSDate','PricePerItem','Discount','Qty_sum']\n","Daily_df = Daily_df[cols]\n","Daily_df"]},{"cell_type":"markdown","metadata":{"id":"1ElQSy7GFg_7"},"source":["### Transactions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YAaB0jMEFg_7"},"outputs":[],"source":["Transactions_df = Daily_df.groupby(['BranchID','ItemID']).agg({'POSDate': 'count'}).sort_values(by=['BranchID','ItemID']).reset_index()\n","Transactions_df = Transactions_df.rename(columns={'POSDate': 'TransactionDays'})\n","Transactions_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IZaVjxKIFg_7"},"outputs":[],"source":["Transactions_filtered = Transactions_df[Transactions_df['TransactionDays'] >= 50]\n","Transactions_filtered"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t7WmaNx_Fg_8"},"outputs":[],"source":["Daily_filtered_df = Daily_df[Daily_df.set_index(['BranchID', 'ItemID']).index.isin(Transactions_filtered.set_index(['BranchID', 'ItemID']).index)]\n","Daily_filtered_df"]},{"cell_type":"markdown","metadata":{"id":"ANFwoP4gFg_8"},"source":["### Holidays"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1NnoZM1xFg_8"},"outputs":[],"source":["holidays = pd.DataFrame({'POSDate': pd.date_range(start=Daily_df['POSDate'].min(), end=Daily_df['POSDate'].max()).tolist()})\n","holidays"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"inv2F0T3Fg_8"},"outputs":[],"source":["def affected_by_holiday(date, holidays):\n","    date = date.to_datetime64()\n","    holidays_date = holidays['Date']\n","    days_to_holiday = date - holidays_date\n","    number_of_holidays = len(days_to_holiday)\n","    affected = [False for i in range(number_of_holidays)]\n","\n","    for i in range(number_of_holidays):\n","        days = days_to_holiday[i]\n","        preparation_days = pd.to_timedelta(holidays['Preparation'][i], unit='D')\n","        aftermath_days = pd.to_timedelta(holidays['Aftermath'][i], unit='D')\n","        if (days < pd.Timedelta(0)) & (days >= -preparation_days):\n","            affected[i] = True\n","        elif (days > pd.Timedelta(0)) & (days <= aftermath_days):\n","            affected[i] = True\n","        else:\n","            affected[i] = holidays['DDay'][i]\n","\n","    return any(affected)\n","\n","holidays['AffectedByHoliday'] = holidays['POSDate'].apply(lambda date: affected_by_holiday(date, Holiday_df))\n","holidays"]},{"cell_type":"markdown","metadata":{"id":"FZ-FP6fnFg_8"},"source":["## Fill in the Blanks"]},{"cell_type":"markdown","metadata":{"id":"8waAya09Fg_8"},"source":["### Full"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HM6R6q30Fg_8"},"outputs":[],"source":["branches_arr = []\n","items_arr = []\n","prices_arr = []\n","dates_arr = []\n","\n","grouped = Daily_df.groupby(['BranchID', 'ItemID'])\n","first_date = Daily_df['POSDate'].min()\n","last_date = Daily_df['POSDate'].max()\n","date_format = '%Y-%m-%d'\n","\n","for (branch, item), group in grouped:\n","    pos_dates = group['POSDate']\n","\n","    start = pos_dates.min()\n","    start_year = start.year\n","    start_month = start.month\n","    start_date = datetime.datetime.strptime(f'{start_year}-{start_month}-01',date_format)\n","    start_date = max(start_date,first_date)\n","\n","    end = pos_dates.max()\n","    end_year = end.year\n","    end_month = end.month\n","    end_date = datetime.datetime.strptime(f'{end_year}-{end_month}-28',date_format) + datetime.timedelta(days=4)\n","    end_date = end_date - datetime.timedelta(days=end_date.day)\n","    end_date = min(end_date,last_date)\n","\n","    date_arr = pd.date_range(start=start_date, end=end_date).tolist()\n","    branch_arr = [branch] * len(date_arr)\n","    item_arr = [item] * len(date_arr)\n","\n","    branch_item_df = pd.DataFrame({'BranchID': branch_arr, 'ItemID': item_arr, 'POSDate': date_arr})\n","    branch_item_df = branch_item_df.merge(group[['BranchID','ItemID','POSDate','PricePerItem']], on=['BranchID', 'ItemID', 'POSDate'], how='left')\n","    branch_item_df['PricePerItem'] = branch_item_df['PricePerItem'].ffill().bfill()\n","    price_arr = branch_item_df['PricePerItem'].astype('int64').to_list()\n","\n","    branches_arr.extend(branch_arr)\n","    items_arr.extend(item_arr)\n","    dates_arr.extend(date_arr)\n","    prices_arr.extend(price_arr)\n","\n","complete = pd.DataFrame({'BranchID': branches_arr, 'ItemID': items_arr, 'POSDate': dates_arr, 'PricePerItem': prices_arr})\n","complete"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"11uOGx0zFg_8"},"outputs":[],"source":["Daily_full_filled = pd.merge(Daily_df, complete, on=['BranchID', 'ItemID', 'POSDate', 'PricePerItem'], how='right')\n","Daily_full_filled = pd.merge(Daily_full_filled, holidays, on=['POSDate'], how='left')\n","Daily_full_filled = Daily_full_filled.fillna({'Qty_sum': 0, 'Discount': False})\n","Daily_full_filled = Daily_full_filled.astype({'Qty_sum': 'int64'})\n","Daily_full_filled['POSDay'] = Daily_full_filled['POSDate'].dt.day\n","Daily_full_filled['POSMonth'] = Daily_full_filled['POSDate'].dt.month\n","Daily_full_filled['POSYear'] = Daily_full_filled['POSDate'].dt.year\n","cols = ['BranchID','ItemID','POSDate','POSDay','POSMonth','POSYear','PricePerItem','Discount','AffectedByHoliday','Qty_sum']\n","Daily_full_filled = Daily_full_filled[cols]\n","Daily_full_filled"]},{"cell_type":"markdown","metadata":{"id":"RaUt9RcDFg_8"},"source":["### Filtered"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FKQusPh3Fg_8"},"outputs":[],"source":["branches_arr = []\n","items_arr = []\n","prices_arr = []\n","dates_arr = []\n","\n","grouped = Daily_filtered_df.groupby(['BranchID', 'ItemID'])\n","first_date = Daily_filtered_df['POSDate'].min()\n","last_date = Daily_filtered_df['POSDate'].max()\n","date_format = '%Y-%m-%d'\n","\n","for (branch, item), group in grouped:\n","    pos_dates = group['POSDate']\n","\n","    start = pos_dates.min()\n","    start_year = start.year\n","    start_month = start.month\n","    start_date = datetime.datetime.strptime(f'{start_year}-{start_month}-01',date_format)\n","    start_date = max(start_date,first_date)\n","\n","    end = pos_dates.max()\n","    end_year = end.year\n","    end_month = end.month\n","    end_date = datetime.datetime.strptime(f'{end_year}-{end_month}-28',date_format) + datetime.timedelta(days=4)\n","    end_date = end_date - datetime.timedelta(days=end_date.day)\n","    end_date = min(end_date,last_date)\n","\n","    date_arr = pd.date_range(start=start_date, end=end_date).tolist()\n","    branch_arr = [branch] * len(date_arr)\n","    item_arr = [item] * len(date_arr)\n","\n","    branch_item_df = pd.DataFrame({'BranchID': branch_arr, 'ItemID': item_arr, 'POSDate': date_arr})\n","    branch_item_df = branch_item_df.merge(group[['BranchID','ItemID','POSDate','PricePerItem']], on=['BranchID', 'ItemID', 'POSDate'], how='left')\n","    branch_item_df['PricePerItem'] = branch_item_df['PricePerItem'].ffill().bfill()\n","    price_arr = branch_item_df['PricePerItem'].astype('int64').to_list()\n","\n","    branches_arr.extend(branch_arr)\n","    items_arr.extend(item_arr)\n","    dates_arr.extend(date_arr)\n","    prices_arr.extend(price_arr)\n","\n","complete = pd.DataFrame({'BranchID': branches_arr, 'ItemID': items_arr, 'POSDate': dates_arr, 'PricePerItem': prices_arr})\n","complete"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eeYlQv7iFg_8"},"outputs":[],"source":["Daily_filtered_filled = pd.merge(Daily_filtered_df, complete, on=['BranchID', 'ItemID', 'POSDate', 'PricePerItem'], how='right')\n","Daily_filtered_filled = pd.merge(Daily_filtered_filled, holidays, on=['POSDate'], how='left')\n","Daily_filtered_filled = Daily_filtered_filled.fillna({'Qty_sum': 0, 'Discount': False})\n","Daily_filtered_filled = Daily_filtered_filled.astype({'Qty_sum': 'int64'})\n","Daily_filtered_filled['POSDay'] = Daily_filtered_filled['POSDate'].dt.day\n","Daily_filtered_filled['POSMonth'] = Daily_filtered_filled['POSDate'].dt.month\n","Daily_filtered_filled['POSYear'] = Daily_filtered_filled['POSDate'].dt.year\n","cols = ['BranchID','ItemID','POSDate','POSDay','POSMonth','POSYear','PricePerItem','Discount','AffectedByHoliday','Qty_sum']\n","Daily_filtered_filled = Daily_filtered_filled[cols]\n","Daily_filtered_filled"]},{"cell_type":"markdown","metadata":{"id":"GiZmpQU4Fg_8"},"source":["### Weekly"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UyNQzV8aFg_8"},"outputs":[],"source":["Weekly_full_filled = Daily_full_filled\n","Weekly_full_filled['POSWeek'] = Weekly_full_filled['POSDate'].dt.isocalendar().week\n","Weekly_full_filled['POSYear'] = Weekly_full_filled['POSDate'].dt.isocalendar().year\n","Weekly_full_filled = Weekly_full_filled.groupby(['BranchID','ItemID','POSYear','POSWeek']).agg(PricePerItem=('PricePerItem','last'), Discount=('Discount','any'), AffectedByHoliday=('AffectedByHoliday','any'), Qty_sum=('Qty_sum','sum')).reset_index()\n","cols = ['BranchID','ItemID','POSWeek','POSYear','PricePerItem','Discount','AffectedByHoliday','Qty_sum']\n","Weekly_full_filled = Weekly_full_filled[cols]\n","Weekly_full_filled"]},{"cell_type":"markdown","metadata":{"id":"uID0dgOtFg_9"},"source":["# Training Model"]},{"cell_type":"markdown","metadata":{"id":"DGqGJVtSFg_9"},"source":["## Import Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dahZrWb7Fg_9"},"outputs":[],"source":["import numpy as np\n","import psutil\n","import xgboost as xgb\n","import matplotlib.pyplot as plt\n","\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import train_test_split\n","from dask.distributed import Client\n","\n","from sklearn.preprocessing import OneHotEncoder\n","import pickle\n","import os\n","\n","client = Client()\n","num_cpu_cores = psutil.cpu_count(logical=False)\n","num_partitions = min(num_cpu_cores, 4)"]},{"cell_type":"markdown","metadata":{"id":"2ttnQzTxFg_9"},"source":["## Feature Selection"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QlCeAhIDFg_9"},"outputs":[],"source":["# Splitting features and target variable\n","X_daily = Daily_filtered_filled[['BranchID', 'ItemID', 'POSDay', 'POSMonth', 'POSYear', 'PricePerItem', 'Discount', 'AffectedByHoliday']]\n","y_daily = Daily_filtered_filled['Qty_sum']\n","\n","X_weekly = Weekly_full_filled[['BranchID', 'ItemID', 'POSWeek', 'POSYear', 'PricePerItem', 'Discount', 'AffectedByHoliday']]\n","y_weekly = Weekly_full_filled['Qty_sum']"]},{"cell_type":"markdown","metadata":{"id":"a1pHntQGFg_9"},"source":["## Encoding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WkiADlPdFg_9"},"outputs":[],"source":["## Daily\n","\n","# Use sparse matrix\n","X_daily_full = Daily_full_filled[['BranchID', 'ItemID', 'POSDay', 'POSMonth', 'POSYear', 'PricePerItem', 'Discount', 'AffectedByHoliday']]\n","encoder_D = OneHotEncoder(sparse_output=True, handle_unknown='ignore')  # Using sparse output to save memory\n","encoder_D.fit(X_daily_full[['BranchID', 'ItemID']])\n","\n","X_daily_encoded = encoder_D.transform(X_daily[['BranchID', 'ItemID']])\n","\n","# Drop original columns earlier to free memory\n","X_daily.drop(columns=['BranchID', 'ItemID'], inplace=True)\n","\n","# Convert the sparse matrix to DataFrame\n","X_daily_encoded_df = pd.DataFrame.sparse.from_spmatrix(X_daily_encoded, columns=encoder_D.get_feature_names_out(['BranchID', 'ItemID']))\n","\n","# Concatenate with original DataFrame\n","X_daily = pd.concat([X_daily, X_daily_encoded_df], axis=1)\n","\n","# Display DataFrame\n","X_daily"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"55Gu_kpsFg_9"},"outputs":[],"source":["## Weekly\n","\n","# Use sparse matrix\n","encoder_W = OneHotEncoder(sparse_output=True, handle_unknown='ignore')  # Using sparse output to save memory\n","X_weekly_encoded = encoder_W.fit_transform(X_weekly[['BranchID', 'ItemID']])\n","\n","# Drop original columns earlier to free memory\n","X_weekly.drop(columns=['BranchID', 'ItemID'], inplace=True)\n","\n","# Convert the sparse matrix to DataFrame\n","X_weekly_encoded_df = pd.DataFrame.sparse.from_spmatrix(X_weekly_encoded, columns=encoder_W.get_feature_names_out(['BranchID', 'ItemID']))\n","\n","# Concatenate with original DataFrame\n","X_weekly = pd.concat([X_weekly, X_weekly_encoded_df], axis=1)\n","\n","# Display DataFrame\n","X_weekly"]},{"cell_type":"markdown","metadata":{"id":"ZwXaw4xMFg_9"},"source":["## Train Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oxMbwnI7FhAA"},"outputs":[],"source":["## Daily\n","\n","X_train_D, X_test_D, y_train_D, y_test_D = train_test_split(X_daily, y_daily, test_size=0.2, random_state=69)\n","# Train XGBoost model with early stopping\n","model_D = xgb.XGBRegressor(n_estimators=500, gamma=2, tree_method='hist',\n","                         eta=0.15, max_depth=3, min_child_weight=2, subsample=0.6)\n","\n","# Train XGBoost model with early stopping\n","eval_set_D = [(X_train_D, y_train_D), (X_test_D, y_test_D)]\n","model_D.fit(X_train_D, y_train_D, early_stopping_rounds=10, eval_set=eval_set_D, verbose=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zAf2osm0FhAB"},"outputs":[],"source":["## Weekly\n","\n","X_train_W, X_test_W, y_train_W, y_test_W = train_test_split(X_weekly, y_weekly, test_size=0.2, random_state=69)\n","# Train XGBoost model with early stopping\n","model_W = xgb.XGBRegressor(n_estimators=600, gamma=3, tree_method='hist', learning_rate=0.05,\n","                         eta=0.07, max_depth=6, min_child_weight=4, subsample=0.8, reg_alpha = 0.2, reg_lambda=0.2)\n","\n","# Train XGBoost model with early stopping\n","eval_set_W = [(X_train_W, y_train_W), (X_test_W, y_test_W)]\n","model_W.fit(X_train_W, y_train_W, early_stopping_rounds=10, eval_set=eval_set_W, verbose=True)"]},{"cell_type":"markdown","metadata":{"id":"ms8ewJiVFhAB"},"source":["## Save Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0p_Htkd4FhAB"},"outputs":[],"source":["with open('xgboost_model_daily.pkl', 'wb') as f:\n","    pickle.dump(model_D, f)\n","\n","with open('xgboost_model_weekly.pkl', 'wb') as f:\n","    pickle.dump(model_W, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0KOeN6uUFhAB"},"outputs":[],"source":["model_D.save_model('xgboost_model_daily.bst')\n","model_W.save_model('xgboost_model_weekly.bst')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}